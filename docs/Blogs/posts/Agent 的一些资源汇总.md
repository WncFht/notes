---
title: Agent
tags:
  - Agent
categories: 
date: 2025-03-15T01:28:00+08:00
modify: 2025-03-15T01:28:00+08:00
dir: 
share: false
cdate: 2025-03-15
mdate: 2025-03-15
---

# Agent

## GitHubËµÑÊ∫ê

- [Awesome SDKs for AI Agents](https://github.com/e2b-dev/awesome-sdks-for-ai-agents) - AI‰ª£ÁêÜSDKÁöÑÁ≤æÈÄâÂàóË°®
- [GitHub - kyrolabs/awesome-agents: ü§ñ Awesome list of AI Agents](https://github.com/kyrolabs/awesome-agents)

### ÂºÄÊ∫êAI‰ª£ÁêÜÈ°πÁõÆ

#### common agent

1. [GitHub - camel-ai/camel: üê´ CAMEL: Finding the Scaling Law of Agents. The first and the best multi-agent framework. https://www.camel-ai.org](https://github.com/camel-ai/camel)
2. [GitHub - myshell-ai/AIlice: AIlice is a fully autonomous, general-purpose AI agent.](https://github.com/myshell-ai/AIlice)
3. [GitHub - microsoft/autogen: A programming framework for agentic AI ü§ñ PyPi: autogen-agentchat Discord: https://aka.ms/autogen-discord Office Hour: https://aka.ms/autogen-officehour](https://github.com/microsoft/autogen)
4. [GitHub - jbexta/AgentPilot: A versatile workflow automation platform to create, organize, and execute AI workflows, from a single LLM to complex AI-driven workflows.](https://github.com/jbexta/AgentPilot)
5. [GitHub - DataBassGit/AgentForge: Extensible AGI Framework](https://github.com/DataBassGit/AgentForge/tree/main)
6. [GitHub - reworkd/AgentGPT: ü§ñ Assemble, configure, and deploy autonomous AI Agents in your browser.](https://github.com/reworkd/AgentGPT)
7. [GitHub - satellitecomponent/Neurite: Fractal Graph-of-Thought. Rhizomatic Mind-Mapping for Ai-Agents, Web-Links, Notes, and Code.](https://github.com/satellitecomponent/Neurite)
8. [GitHub - geekan/MetaGPT: üåü The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming](https://github.com/geekan/MetaGPT)

#### others

1. [GitHub - calcom/cal.com: Scheduling infrastructure for absolutely everyone.](https://github.com/calcom/cal.com)
2. [GitHub - HumanSignal/Adala: Adala: Autonomous DAta (Labeling) Agent framework](https://github.com/HumanSignal/Adala)

#### role play

1. [GitHub - crewAIInc/crewAI: Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.](https://github.com/crewAIInc/crewAI)

#### code

1. [GitHub - sourcegraph/cody: Type less, code more: Cody is an AI code assistant that uses advanced search and codebase context to help you write and fix code.](https://github.com/sourcegraph/cody)
2. [GitHub - ajhous44/cody: Cody the coding ai assistant](https://github.com/ajhous44/cody)
3. [GitHub - continuedev/continue: ‚è© Create, share, and use custom AI code assistants with our open-source IDE extensions and hub of models, rules, prompts, docs, and other building blocks](https://github.com/continuedev/continue)
4. [GitHub - Aider-AI/aider: aider is AI pair programming in your terminal](https://github.com/Aider-AI/aider)

#### ‰∏çÊõ¥Êñ∞ÁöÑ

1. [GitHub - codefuse-ai/codefuse-chatbot: An intelligent assistant serving the entire software development lifecycle, powered by a Multi-Agent Framework, working with DevOps Toolkits, Code&Doc Repo RAG, etc.](https://github.com/codefuse-ai/codefuse-chatbot)
2. [GitHub - ennucore/clippinator: AI programming assistant](https://github.com/ennucore/clippinator)
3. [GitHub - ur-whitelab/chemcrow-public: Chemcrow](https://github.com/ur-whitelab/chemcrow-public)
4. [GitHub - Technion-Kishony-lab/data-to-paper: data-to-paper: Backward-traceable AI-driven scientific research](https://github.com/Technion-Kishony-lab/data-to-paper)
5. [GitHub - stitionai/devika: Devika is an Agentic AI Software Engineer that can understand high-level human instructions, break them down into steps, research relevant information, and write code to achieve the given objective. Devika aims to be a competitive open-source alternative to Devin by Cognition AI. \[‚ö†Ô∏è DEVIKA DOES NOT HAVE AN OFFICIAL WEBSITE ‚ö†Ô∏è\]](https://github.com/stitionai/devika)
6. [GitHub - jina-ai/dev-gpt: Your Virtual Development Team](https://github.com/jina-ai/dev-gpt)
7. [GitHub - melih-unsal/DemoGPT: ü§ñ Everything you need to create an LLM Agent‚Äîtools, prompts, frameworks, and models‚Äîall in one place.](https://github.com/melih-unsal/DemoGPT)
8. [GitHub - Farama-Foundation/chatarena: ChatArena (or Chat Arena) is a Multi-Agent Language Game Environments for LLMs. The goal is to develop communication and collaboration capabilities of AIs.](https://github.com/Farama-Foundation/chatarena)
9. [GitHub - OpenBMB/ChatDev: Create Customized Software using Natural Language Idea (through LLM-powered Multi-Agent Collaboration)](https://github.com/OpenBMB/ChatDev)
10. [GitHub - seahyinghang8/blinky: An open-source debugging agent in VSCode](https://github.com/seahyinghang8/blinky)
11. [GitHub - BloopAI/bloop: bloop is a fast code search engine written in Rust.](https://github.com/BloopAI/bloop)
12. [GitHub - krohling/bondai](https://github.com/krohling/bondai)
13. [GitHub - xeol-io/bumpgen: bumpgen is an AI agent that upgrades npm packages](https://github.com/xeol-io/bumpgen)
14. [GitHub - yoheinakajima/babyagi](https://github.com/yoheinakajima/babyagi)
15. [GitHub - pgalko/BambooAI: A Python library powered by Language Models (LLMs) for conversational data discovery and analysis.](https://github.com/pgalko/BambooAI)
16. [GitHub - AutoPackAI/beebot: An Autonomous AI Agent that works](https://github.com/AutoPackAI/beebot)
17. [GitHub - stepanogil/autonomous-hr-chatbot: An autonomous HR agent that can answer user queries using tools](https://github.com/stepanogil/autonomous-hr-chatbot)
18. [GitHub - irgolic/AutoPR: Run AI-powered workflows over your codebase](https://github.com/irgolic/AutoPR)
19. [GitHub - emrgnt-cmplxty/automata: Automata: A self-coding agent](https://github.com/emrgnt-cmplxty/automata)
20. [GitHub - aiwaves-cn/agents: An Open-source Framework for Data-centric, Self-evolving Autonomous Language Agents](https://github.com/aiwaves-cn/agents)
21. [GitHub - eumemic/ai-legion: An LLM-powered autonomous agent platform](https://github.com/eumemic/ai-legion)
22. [GitHub - LehengTHU/Agent4Rec: \[SIGIR 2024 perspective\] The implementation of paper "On Generative Agents in Recommendation"](https://github.com/LehengTHU/Agent4Rec)

## Paper Ê±áÊÄª

1. Bergman, S., Ji, Z., Kermarrec, A.-M., Petrescu, D., Pires, R., Randl, M., & Vos, M. de. (2025). _Leveraging Approximate Caching for Faster Retrieval-Augmented Generation_. [https://doi.org/10.1145/3721146.3721941](https://doi.org/10.1145/3721146.3721941)
2. Cai, Y., Guo, Z., Pei, Y., Bian, W., & Zheng, W. (2024). _SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation_ (No. arXiv: 2412.15272). arXiv. [https://doi.org/10.48550/arXiv.2412.15272](https://doi.org/10.48550/arXiv.2412.15272)
3. Chen, B., Guo, Z., Yang, Z., Chen, Y., Chen, J., Liu, Z., Shi, C., & Yang, C. (2025). _PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths_ (No. arXiv: 2502.14902). arXiv. [https://doi.org/10.48550/arXiv.2502.14902](https://doi.org/10.48550/arXiv.2502.14902)
4. Cheng, Y., Zhao, Y., Zhu, J., Liu, Y., Sun, X., & Li, X. (2025). _Human Cognition Inspired RAG with Knowledge Graph for Complex Problem Solving_ (No. arXiv: 2503.06567). arXiv. [https://doi.org/10.48550/arXiv.2503.06567](https://doi.org/10.48550/arXiv.2503.06567)
5. Geng, X., Wang, H., Wang, J., Liu, W., & Li, R. (2025). _Enhancing RAG with Active Learning on Conversation Records: Reject Incapables and Answer Capables_ (No. arXiv: 2502.09073). arXiv. [https://doi.org/10.48550/arXiv.2502.09073](https://doi.org/10.48550/arXiv.2502.09073)
6. Guan, X., Zeng, J., Meng, F., Xin, C., Lu, Y., Lin, H., Han, X., Sun, L., & Zhou, J. (2025). _DeepRAG: Thinking to Retrieval Step by Step for Large Language Models_ (No. arXiv: 2502.01142). arXiv. [https://doi.org/10.48550/arXiv.2502.01142](https://doi.org/10.48550/arXiv.2502.01142)
7. Guti√©rrez, B. J., Shu, Y., Qi, W., Zhou, S., & Su, Y. (2025). _From RAG to Memory: Non-Parametric Continual Learning for Large Language Models_ (No. arXiv: 2502.14802). arXiv. [https://doi.org/10.48550/arXiv.2502.14802](https://doi.org/10.48550/arXiv.2502.14802)
8. Han, H., Shomer, H., Wang, Y., Lei, Y., Guo, K., Hua, Z., Long, B., Liu, H., & Tang, J. (2025). _RAG vs. GraphRAG: A Systematic Evaluation and Key Insights_ (No. arXiv: 2502.11371). arXiv. [https://doi.org/10.48550/arXiv.2502.11371](https://doi.org/10.48550/arXiv.2502.11371)
9. Han, H., Wang, Y., Shomer, H., Guo, K., Ding, J., Lei, Y., Halappanavar, M., Rossi, R. A., Mukherjee, S., Tang, X., He, Q., Hua, Z., Long, B., Zhao, T., Shah, N., Javari, A., Xia, Y., & Tang, J. (2025). _Retrieval-Augmented Generation with Graphs (GraphRAG)_ (No. arXiv: 2501.00309). arXiv. [https://doi.org/10.48550/arXiv.2501.00309](https://doi.org/10.48550/arXiv.2501.00309)
10. Huang, H., Huang, Y., Yang, J., Pan, Z., Chen, Y., Ma, K., Chen, H., & Cheng, J. (2025). _Retrieval-Augmented Generation with Hierarchical Knowledge_ (No. arXiv: 2503.10150). arXiv. [https://doi.org/10.48550/arXiv.2503.10150](https://doi.org/10.48550/arXiv.2503.10150)
11. Huang, S., Ma, Z., Du, J., Meng, C., Wang, W., Leng, J., Guo, M., & Lin, Z. (2025). _Gumbel Reranking: Differentiable End-to-End Reranker Optimization_ (No. arXiv: 2502.11116). arXiv. [https://doi.org/10.48550/arXiv.2502.11116](https://doi.org/10.48550/arXiv.2502.11116)
12. Huang, Y., Zhang, S., & Xiao, X. (2025). _KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework for Graph-RAG_ (No. arXiv: 2502.09304). arXiv. [https://doi.org/10.48550/arXiv.2502.09304](https://doi.org/10.48550/arXiv.2502.09304)
13. Lee, M.-C., Zhu, Q., Mavromatis, C., Han, Z., Adeshina, S., Ioannidis, V. N., Rangwala, H., & Faloutsos, C. (2024). _HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases_ (No. arXiv: 2412.16311). arXiv. [https://doi.org/10.48550/arXiv.2412.16311](https://doi.org/10.48550/arXiv.2412.16311)
14. Li, M., Gaussier, E., & Zhou, G. (2025). _Enhanced Retrieval of Long Documents: Leveraging Fine-Grained Block Representations with Large Language Models_ (No. arXiv: 2501.17039). arXiv. [https://doi.org/10.48550/arXiv.2501.17039](https://doi.org/10.48550/arXiv.2501.17039)
15. Li, X., Cao, Y., Ma, Y., & Sun, A. (2024). _Long Context vs. RAG for LLMs: An Evaluation and Revisits_ (No. arXiv: 2501.01880). arXiv. [https://doi.org/10.48550/arXiv.2501.01880](https://doi.org/10.48550/arXiv.2501.01880)
16. Lin, C.-Y., Kamahori, K., Liu, Y., Shi, X., Kashyap, M., Gu, Y., Shao, R., Ye, Z., Zhu, K., Wang, S., Krishnamurthy, A., Kadekodi, R., Ceze, L., & Kasikci, B. (2025). _TeleRAG: Efficient Retrieval-Augmented Generation Inference with Lookahead Retrieval_ (No. arXiv: 2502.20969). arXiv. [https://doi.org/10.48550/arXiv.2502.20969](https://doi.org/10.48550/arXiv.2502.20969)
17. Liu, H., Wang, Z., Chen, X., Li, Z., Xiong, F., Yu, Q., & Zhang, W. (2025). _HopRAG: Multi-Hop Reasoning for Logic-Aware Retrieval-Augmented Generation_ (No. arXiv: 2502.12442). arXiv. [https://doi.org/10.48550/arXiv.2502.12442](https://doi.org/10.48550/arXiv.2502.12442)
18. Lumer, E., Basavaraju, P. H., Mason, M., Burke, J. A., & Subbiah, V. K. (2025). _Graph RAG-Tool Fusion_ (No. arXiv: 2502.07223). arXiv. [https://doi.org/10.48550/arXiv.2502.07223](https://doi.org/10.48550/arXiv.2502.07223)
19. Luo, L., Zhao, Z., Haffari, G., Phung, D., Gong, C., & Pan, S. (2025). _GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation_ (No. arXiv: 2502.01113). arXiv. [https://doi.org/10.48550/arXiv.2502.01113](https://doi.org/10.48550/arXiv.2502.01113)
20. Mahalingam, A., Gande, V. K., Chadha, A., Jain, V., & Chaudhary, D. (2024). _SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval_ (No. arXiv: 2412.15443). arXiv. [https://doi.org/10.48550/arXiv.2412.15443](https://doi.org/10.48550/arXiv.2412.15443)
21. Mukherjee, M., Kim, S., Chen, X., Luo, D., Yu, T., & Mai, T. (2025). _From Documents to Dialogue: Building KG-RAG Enhanced AI Assistants_ (No. arXiv: 2502.15237). arXiv. [https://doi.org/10.48550/arXiv.2502.15237](https://doi.org/10.48550/arXiv.2502.15237)
22. Myers, A., Vargas, M., Aksoy, S. G., Joslyn, C., Wilson, B., & Grimes, T. (2025). _Talking to GDELT Through Knowledge Graphs_ (No. arXiv: 2503.07584). arXiv. [https://doi.org/10.48550/arXiv.2503.07584](https://doi.org/10.48550/arXiv.2503.07584)
23. Ni, B., Liu, Z., Wang, L., Lei, Y., Zhao, Y., Cheng, X., Zeng, Q., Dong, L., Xia, Y., Kenthapadi, K., Rossi, R., Dernoncourt, F., Tanjim, M. M., Ahmed, N., Liu, X., Fan, W., Blasch, E., Wang, Y., Jiang, M., & Derr, T. (2025). _Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey_ (No. arXiv: 2502.06872). arXiv. [https://doi.org/10.48550/arXiv.2502.06872](https://doi.org/10.48550/arXiv.2502.06872)
24. Singh, A., Ehtesham, A., Kumar, S., & Khoei, T. T. (2025). _Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG_ (No. arXiv: 2501.09136). arXiv. [https://doi.org/10.48550/arXiv.2501.09136](https://doi.org/10.48550/arXiv.2501.09136)
25. Wang, H., Feng, Y., Xie, X., & Zhou, S. K. (2025). _Path Pooling: Train-Free Structure Enhancement for Efficient Knowledge Graph Retrieval-Augmented Generation_ (No. arXiv: 2503.05203). arXiv. [https://doi.org/10.48550/arXiv.2503.05203](https://doi.org/10.48550/arXiv.2503.05203)
26. Wang, S., Fang, Y., Zhou, Y., Liu, X., & Ma, Y. (2025). _ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation_ (No. arXiv: 2502.09891). arXiv. [https://doi.org/10.48550/arXiv.2502.09891](https://doi.org/10.48550/arXiv.2502.09891)
27. Yin, C., Wei, E., Zhang, Z., & Zhan, Z. (2025). _PaperHelper: Knowledge-Based LLM QA Paper Reading Assistant_ (No. arXiv: 2502.14271). arXiv. [https://doi.org/10.48550/arXiv.2502.14271](https://doi.org/10.48550/arXiv.2502.14271)
28. Yuan, X., Liu, Y., Di, S., Wu, S., Zheng, L., Meng, R., Chen, L., Zhou, X., & Yin, J. (2025). _A Pilot Empirical Study on When and How to Use Knowledge Graphs as Retrieval Augmented Generation_ (No. arXiv: 2502.20854). arXiv. [https://doi.org/10.48550/arXiv.2502.20854](https://doi.org/10.48550/arXiv.2502.20854)
29. Zhang, J., Liu, Y., Wang, W., Liu, Q., Wu, S., Wang, L., & Chua, T.-S. (2025). _Personalized Text Generation with Contrastive Activation Steering_ (No. arXiv: 2503.05213). arXiv. [https://doi.org/10.48550/arXiv.2503.05213](https://doi.org/10.48550/arXiv.2503.05213)
30. Zhang, Z., Feng, Y., & Zhang, M. (2025). _LevelRAG: Enhancing Retrieval-Augmented Generation with Multi-hop Logic Planning over Rewriting Augmented Searchers_ (No. arXiv: 2502.18139). arXiv. [https://doi.org/10.48550/arXiv.2502.18139](https://doi.org/10.48550/arXiv.2502.18139)
31. Zhao, J., Ji, Z., Fan, Z., Wang, H., Niu, S., Tang, B., Xiong, F., & Li, Z. (2025). _MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented Generation System_ (No. arXiv: 2503.09600). arXiv. [https://doi.org/10.48550/arXiv.2503.09600](https://doi.org/10.48550/arXiv.2503.09600)
32. Zheng, Z., Ni, X., & Hong, P. (2025). _Multiple Abstraction Level Retrieve Augment Generation_ (No. arXiv: 2501.16952). arXiv. [https://doi.org/10.48550/arXiv.2501.16952](https://doi.org/10.48550/arXiv.2501.16952)
33. Zhou, J., & Chen, L. (2025). _OpenRAG: Optimizing RAG End-to-End via In-Context Retrieval Learning_ (No. arXiv: 2503.08398). arXiv. [https://doi.org/10.48550/arXiv.2503.08398](https://doi.org/10.48550/arXiv.2503.08398)
34. Zhou, Y., Su, Y., Sun, Y., Wang, S., Wang, T., He, R., Zhang, Y., Liang, S., Liu, X., Ma, Y., & Fang, Y. (2025). _In-depth Analysis of Graph-based RAG in a Unified Framework_ (No. arXiv: 2503.04338). arXiv. [https://doi.org/10.48550/arXiv.2503.04338](https://doi.org/10.48550/arXiv.2503.04338)
35. Zhu, X., Xie, Y., Liu, Y., Li, Y., & Hu, W. (2025). _Knowledge Graph-Guided Retrieval Augmented Generation_ (No. arXiv: 2502.06864). arXiv. [https://doi.org/10.48550/arXiv.2502.06864](https://doi.org/10.48550/arXiv.2502.06864)
36. Alonso, N., Figliolia, T., Ndirango, A., & Millidge, B. (2024). _Toward Conversational Agents with Context and Time Sensitive Long-term Memory_ (No. arXiv: 2406.00057). arXiv. [https://doi.org/10.48550/arXiv.2406.00057](https://doi.org/10.48550/arXiv.2406.00057)
37. Anokhin, P., Semenov, N., Sorokin, A., Evseev, D., Burtsev, M., & Burnaev, E. (2024). _AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents_ (No. arXiv: 2407.04363). arXiv. [https://doi.org/10.48550/arXiv.2407.04363](https://doi.org/10.48550/arXiv.2407.04363)
38. Chen, H., Pasunuru, R., Weston, J., & Celikyilmaz, A. (2023). _Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading_ (No. arXiv: 2310.05029). arXiv. [https://doi.org/10.48550/arXiv.2310.05029](https://doi.org/10.48550/arXiv.2310.05029)
39. Chen, S., Zhao, Z., Zhao, Y., & Li, X. (2024). _Apollonion: Profile-centric Dialog Agent_ (No. arXiv: 2404.08692). arXiv. [https://doi.org/10.48550/arXiv.2404.08692](https://doi.org/10.48550/arXiv.2404.08692)
40. Gao, H., & Zhang, Y. (2024). _Memory Sharing for Large Language Model based Agents_ (No. arXiv: 2404.09982). arXiv. [https://doi.org/10.48550/arXiv.2404.09982](https://doi.org/10.48550/arXiv.2404.09982)
41. Guo, J., Li, N., Qi, J., Yang, H., Li, R., Feng, Y., Zhang, S., & Xu, M. (2024). _Empowering Working Memory for Large Language Model Agents_ (No. arXiv: 2312.17259). arXiv. [https://doi.org/10.48550/arXiv.2312.17259](https://doi.org/10.48550/arXiv.2312.17259)
42. Guti√©rrez, B. J., Shu, Y., Gu, Y., Yasunaga, M., & Su, Y. (2025). _HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models_ (No. arXiv: 2405.14831). arXiv. [https://doi.org/10.48550/arXiv.2405.14831](https://doi.org/10.48550/arXiv.2405.14831)
43. Hou, Y., Tamoto, H., & Miyashita, H. (2024). „ÄäMy agent understands me better„Äã: Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents. _Extended Abstracts of the CHI Conference on Human Factors in Computing Systems_, 1‚Äì7. [https://doi.org/10.1145/3613905.3650839](https://doi.org/10.1145/3613905.3650839)
44. Hu, M., Chen, T., Chen, Q., Mu, Y., Shao, W., & Luo, P. (2024). _HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model_ (No. arXiv: 2408.09559). arXiv. [https://doi.org/10.48550/arXiv.2408.09559](https://doi.org/10.48550/arXiv.2408.09559)
45. Hu, P., & Ying, X. (2025). _Unified Mind Model: Reimagining Autonomous Agents in the LLM Era_ (No. arXiv: 2503.03459). arXiv. [https://doi.org/10.48550/arXiv.2503.03459](https://doi.org/10.48550/arXiv.2503.03459)
46. Jiang, J., Zhou, K., Zhao, W. X., Song, Y., Zhu, C., Zhu, H., & Wen, J.-R. (2024). _KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph_ (No. arXiv: 2402.11163). arXiv. [https://doi.org/10.48550/arXiv.2402.11163](https://doi.org/10.48550/arXiv.2402.11163)
47. Jiang, X., Li, F., Zhao, H., Wang, J., Shao, J., Xu, S., Zhang, S., Chen, W., Tang, X., Chen, Y., Wu, M., Ma, W., Wang, M., & Chen, T. (2024). _Long Term Memory: The Foundation of AI Self-Evolution_ (No. arXiv: 2410.15665). arXiv. [https://doi.org/10.48550/arXiv.2410.15665](https://doi.org/10.48550/arXiv.2410.15665)
48. Kim, T., Fran√ßois-Lavet, V., & Cochez, M. (2024). _Leveraging Knowledge Graph-Based Human-Like Memory Systems to Solve Partially Observable Markov Decision Processes_ (No. arXiv: 2408.05861). arXiv. [https://doi.org/10.48550/arXiv.2408.05861](https://doi.org/10.48550/arXiv.2408.05861)
49. Li, H., Yang, C., Zhang, A., Deng, Y., Wang, X., & Chua, T.-S. (2025). _Hello Again! LLM-powered Personalized Agent for Long-term Dialogue_ (No. arXiv: 2406.05925). arXiv. [https://doi.org/10.48550/arXiv.2406.05925](https://doi.org/10.48550/arXiv.2406.05925)
50. Liang, X., Tao, M., Xia, Y., Shi, T., Wang, J., & Yang, J. (2024). _Self-evolving Agents with reflective and memory-augmented abilities_ (No. arXiv: 2409.00872). arXiv. [https://doi.org/10.48550/arXiv.2409.00872](https://doi.org/10.48550/arXiv.2409.00872)
51. Liu, J., Gu, S., Li, D., Zhang, G., Han, M., Gu, H., Zhang, P., Lu, T., Shang, L., & Gu, N. (2025). _Enhancing Cross-Domain Recommendations with Memory-Optimized LLM-Based User Agents_ (No. arXiv: 2502.13843). arXiv. [https://doi.org/10.48550/arXiv.2502.13843](https://doi.org/10.48550/arXiv.2502.13843)
52. Liu, L., Yang, X., Shen, Y., Hu, B., Zhang, Z., Gu, J., & Zhang, G. (2023). _Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory_ (No. arXiv: 2311.08719). arXiv. [https://doi.org/10.48550/arXiv.2311.08719](https://doi.org/10.48550/arXiv.2311.08719)
53. Liu, N., Chen, L., Tian, X., Zou, W., Chen, K., & Cui, M. (2024). _From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models_ (No. arXiv: 2401.02777). arXiv. [https://doi.org/10.48550/arXiv.2401.02777](https://doi.org/10.48550/arXiv.2401.02777)
54. Liu, W., Zhang, R., Zhou, A., Gao, F., & Liu, J. (2025). _Echo: A Large Language Model with Temporal Episodic Memory_ (No. arXiv: 2502.16090). arXiv. [https://doi.org/10.48550/arXiv.2502.16090](https://doi.org/10.48550/arXiv.2502.16090)
55. Maharana, A., Lee, D.-H., Tulyakov, S., Bansal, M., Barbieri, F., & Fang, Y. (2024). _Evaluating Very Long-Term Conversational Memory of LLM Agents_ (No. arXiv: 2402.17753). arXiv. [https://doi.org/10.48550/arXiv.2402.17753](https://doi.org/10.48550/arXiv.2402.17753)
56. McKee, K. L. (2025). _Meta-Learning to Explore via Memory Density Feedback_ (No. arXiv: 2503.02831). arXiv. [https://doi.org/10.48550/arXiv.2503.02831](https://doi.org/10.48550/arXiv.2503.02831)
57. Michelman, J., Baratalipour, N., & Abueg, M. (2025). _Enhancing Reasoning with Collaboration and Memory_ (No. arXiv: 2503.05944). arXiv. [https://doi.org/10.48550/arXiv.2503.05944](https://doi.org/10.48550/arXiv.2503.05944)
58. Mumuni, A., & Mumuni, F. (2025). _Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches_ (No. arXiv: 2501.03151). arXiv. [https://doi.org/10.48550/arXiv.2501.03151](https://doi.org/10.48550/arXiv.2501.03151)
59. Ong, K. T., Kim, N., Gwak, M., Chae, H., Kwon, T., Jo, Y., Hwang, S., Lee, D., & Yeo, J. (2025). _Towards Lifelong Dialogue Agents via Timeline-based Memory Management_ (No. arXiv: 2406.10996). arXiv. [https://doi.org/10.48550/arXiv.2406.10996](https://doi.org/10.48550/arXiv.2406.10996)
60. Pan, H., Zhai, Z., Yuan, H., Lv, Y., Fu, R., Liu, M., Wang, Z., & Qin, B. (2024). _KwaiAgents: Generalized Information-seeking Agent System with Large Language Models_ (No. arXiv: 2312.04889). arXiv. [https://doi.org/10.48550/arXiv.2312.04889](https://doi.org/10.48550/arXiv.2312.04889)
61. Pan, Z., Wu, Q., Jiang, H., Luo, X., Cheng, H., Li, D., Yang, Y., Lin, C.-Y., Zhao, H. V., Qiu, L., & Gao, J. (2025). _On Memory Construction and Retrieval for Personalized Conversational Agents_ (No. arXiv: 2502.05589). arXiv. [https://doi.org/10.48550/arXiv.2502.05589](https://doi.org/10.48550/arXiv.2502.05589)
62. Peng, Q., Liu, H., Huang, H., Yang, Q., & Shao, M. (2025). _A Survey on LLM-powered Agents for Recommender Systems_ (No. arXiv: 2502.10050). arXiv. [https://doi.org/10.48550/arXiv.2502.10050](https://doi.org/10.48550/arXiv.2502.10050)
63. Pink, M., Wu, Q., Vo, V. A., Turek, J., Mu, J., Huth, A., & Toneva, M. (2025). _Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents_ (No. arXiv: 2502.06975). arXiv. [https://doi.org/10.48550/arXiv.2502.06975](https://doi.org/10.48550/arXiv.2502.06975)
64. Rappazzo, B. H., Wang, Y., Ferber, A., & Gomes, C. (2024). _GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation_ (No. arXiv: 2409.15566). arXiv. [https://doi.org/10.48550/arXiv.2409.15566](https://doi.org/10.48550/arXiv.2409.15566)
65. Rasmussen, P., Paliychuk, P., Beauvais, T., Ryan, J., & Chalef, D. (2025). _Zep: A Temporal Knowledge Graph Architecture for Agent Memory_ (No. arXiv: 2501.13956). arXiv. [https://doi.org/10.48550/arXiv.2501.13956](https://doi.org/10.48550/arXiv.2501.13956)
66. Schmied, T., Paischer, F., Patil, V., Hofmarcher, M., Pascanu, R., & Hochreiter, S. (2024). _Retrieval-Augmented Decision Transformer: External Memory for In-context RL_ (No. arXiv: 2410.07071). arXiv. [https://doi.org/10.48550/arXiv.2410.07071](https://doi.org/10.48550/arXiv.2410.07071)
67. Shang, J., Zheng, Z., Wei, J., Ying, X., Tao, F., & Team, M. (2024). _AI-native Memory: A Pathway from LLMs Towards AGI_ (No. arXiv: 2406.18312). arXiv. [https://doi.org/10.48550/arXiv.2406.18312](https://doi.org/10.48550/arXiv.2406.18312)
68. Singh, A., Ehtesham, A., Kumar, S., & Khoei, T. T. (2025). _Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG_ (No. arXiv: 2501.09136). arXiv. [https://doi.org/10.48550/arXiv.2501.09136](https://doi.org/10.48550/arXiv.2501.09136)
69. Sumers, T. R., Yao, S., Narasimhan, K., & Griffiths, T. L. (2024). _Cognitive Architectures for Language Agents_ (No. arXiv: 2309.02427). arXiv. [https://doi.org/10.48550/arXiv.2309.02427](https://doi.org/10.48550/arXiv.2309.02427)
70. Sun, Y., Fu, H., Littman, M., & Konidaris, G. (2025). _Knowledge Retention for Continual Model-Based Reinforcement Learning_ (No. arXiv: 2503.04256). arXiv. [https://doi.org/10.48550/arXiv.2503.04256](https://doi.org/10.48550/arXiv.2503.04256)
71. Tan, J. C. M., Saroj, P., Runwal, B., Maheshwari, H., Sheng, B. L. Y., Cottrill, R., Chona, A., Kumar, A., & Motani, M. (2024). _TaskGen: A Task-Based, Memory-Infused Agentic Framework using StrictJSON_ (No. arXiv: 2407.15734). arXiv. [https://doi.org/10.48550/arXiv.2407.15734](https://doi.org/10.48550/arXiv.2407.15734)
72. Tan, Z., Yan, J., Hsu, I.-H., Han, R., Wang, Z., Le, L. T., Song, Y., Chen, Y., Palangi, H., Lee, G., Iyer, A., Chen, T., Liu, H., Lee, C.-Y., & Pfister, T. (2025). _In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents_ (No. arXiv: 2503.08026). arXiv. [https://doi.org/10.48550/arXiv.2503.08026](https://doi.org/10.48550/arXiv.2503.08026)
73. Wang, P., Li, Z., Zhang, N., Xu, Z., Yao, Y., Jiang, Y., Xie, P., Huang, F., & Chen, H. (2024). _WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models_ (No. arXiv: 2405.14768). arXiv. [https://doi.org/10.48550/arXiv.2405.14768](https://doi.org/10.48550/arXiv.2405.14768)
74. Wang, Q., Gao, Z., & Xu, R. (2023). _Graph Agent: Explicit Reasoning Agent for Graphs_ (No. arXiv: 2310.16421). arXiv. [https://doi.org/10.48550/arXiv.2310.16421](https://doi.org/10.48550/arXiv.2310.16421)
75. Wang, X., Wang, S., Zhu, Y., & Liu, B. (2025). _R $^3$ Mem: Bridging Memory Retention and Retrieval via Reversible Compression_ (No. arXiv: 2502.15957). arXiv. [https://doi.org/10.48550/arXiv.2502.15957](https://doi.org/10.48550/arXiv.2502.15957)
76. Wang, Z. Z., Mao, J., Fried, D., & Neubig, G. (2024). _Agent Workflow Memory_ (No. arXiv: 2409.07429). arXiv. [https://doi.org/10.48550/arXiv.2409.07429](https://doi.org/10.48550/arXiv.2409.07429)
77. Wei, J., Ying, X., Gao, T., Bao, F., Tao, F., & Shang, J. (2025). _AI-native Memory 2.0: Second Me_ (No. arXiv: 2503.08102). arXiv. [https://doi.org/10.48550/arXiv.2503.08102](https://doi.org/10.48550/arXiv.2503.08102)
78. Xu, W., Liang, Z., Mei, K., Gao, H., Tan, J., & Zhang, Y. (2025). _A-MEM: Agentic Memory for LLM Agents_ (No. arXiv: 2502.12110). arXiv. [https://doi.org/10.48550/arXiv.2502.12110](https://doi.org/10.48550/arXiv.2502.12110)
79. Yan, X., Feng, S., Yuan, J., Xia, R., Wang, B., Zhang, B., & Bai, L. (2025). _SurveyForge: On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing_ (No. arXiv: 2503.04629). arXiv. [https://doi.org/10.48550/arXiv.2503.04629](https://doi.org/10.48550/arXiv.2503.04629)
80. Yang, H., Lin, Z., Wang, W., Wu, H., Li, Z., Tang, B., Wei, W., Wang, J., Tang, Z., Song, S., Xi, C., Yu, Y., Chen, K., Xiong, F., Tang, L., & E, W. (2024). $\text{Memory}^3$ : Language Modeling with Explicit Memory. _Journal of Machine Learning_, _3_(3), 300‚Äì346. [https://doi.org/10.4208/jml.240708](https://doi.org/10.4208/jml.240708)
81. Yang, W., Li, Y., Fang, M., & Chen, L. (2025). _MTPChat: A Multimodal Time-Aware Persona Dataset for Conversational Agents_ (No. arXiv: 2502.05887). arXiv. [https://doi.org/10.48550/arXiv.2502.05887](https://doi.org/10.48550/arXiv.2502.05887)
82. Yue, S., Wang, S., Chen, W., Huang, X., & Wei, Z. (2025). _Synergistic Multi-Agent Framework with Trajectory Learning for Knowledge-Intensive Tasks_ (No. arXiv: 2407.09893). arXiv. [https://doi.org/10.48550/arXiv.2407.09893](https://doi.org/10.48550/arXiv.2407.09893)
83. Zeng, R., Fang, J., Liu, S., & Meng, Z. (2024). _On the Structural Memory of LLM Agents_ (No. arXiv: 2412.15266). arXiv. [https://doi.org/10.48550/arXiv.2412.15266](https://doi.org/10.48550/arXiv.2412.15266)
84. Zhang, Y., Chen, Z., Guo, L., Xu, Y., Zhang, W., & Chen, H. (2024). _Making Large Language Models Perform Better in Knowledge Graph Completion_ (No. arXiv: 2310.06671). arXiv. [https://doi.org/10.48550/arXiv.2310.06671](https://doi.org/10.48550/arXiv.2310.06671)
85. Zhang, Z., Bo, X., Ma, C., Li, R., Chen, X., Dai, Q., Zhu, J., Dong, Z., & Wen, J.-R. (2024). _A Survey on the Memory Mechanism of Large Language Model based Agents_ (No. arXiv: 2404.13501). arXiv. [https://doi.org/10.48550/arXiv.2404.13501](https://doi.org/10.48550/arXiv.2404.13501)
86. Zheng, J., Shi, C., Cai, X., Li, Q., Zhang, D., Li, C., Yu, D., & Ma, Q. (2025). _Lifelong Learning of Large Language Model based Agents: A Roadmap_ (No. arXiv: 2501.07278). arXiv. [https://doi.org/10.48550/arXiv.2501.07278](https://doi.org/10.48550/arXiv.2501.07278)
87. Zhong, W., Guo, L., Gao, Q., Ye, H., & Wang, Y. (2023). _MemoryBank: Enhancing Large Language Models with Long-Term Memory_ (No. arXiv: 2305.10250). arXiv. [https://doi.org/10.48550/arXiv.2305.10250](https://doi.org/10.48550/arXiv.2305.10250)
88. Bran, A. M., Cox, S., Schilter, O., Baldassari, C., White, A. D., & Schwaller, P. (2023). _ChemCrow: Augmenting large-language models with chemistry tools_ (No. arXiv: 2304.05376). arXiv. [https://doi.org/10.48550/arXiv.2304.05376](https://doi.org/10.48550/arXiv.2304.05376)
89. Chen, W., Su, Y., Zuo, J., Yang, C., Yuan, C., Chan, C.-M., Yu, H., Lu, Y., Hung, Y.-H., Qian, C., Qin, Y., Cong, X., Xie, R., Liu, Z., Sun, M., & Zhou, J. (2023). _AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors_ (No. arXiv: 2308.10848). arXiv. [https://doi.org/10.48550/arXiv.2308.10848](https://doi.org/10.48550/arXiv.2308.10848)
90. Du, Y., Li, S., Torralba, A., Tenenbaum, J. B., & Mordatch, I. (2023). _Improving Factuality and Reasoning in Language Models through Multiagent Debate_ (No. arXiv: 2305.14325). arXiv. [https://doi.org/10.48550/arXiv.2305.14325](https://doi.org/10.48550/arXiv.2305.14325)
91. Ge, Y., Hua, W., Mei, K., Ji, J., Tan, J., Xu, S., Li, Z., & Zhang, Y. (2023). _OpenAGI: When LLM Meets Domain Experts_ (No. arXiv: 2304.04370). arXiv. [https://doi.org/10.48550/arXiv.2304.04370](https://doi.org/10.48550/arXiv.2304.04370)
92. Guo, J., Yang, B., Yoo, P., Lin, B. Y., Iwasawa, Y., & Matsuo, Y. (2024). _Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4_ (No. arXiv: 2309.17277). arXiv. [https://doi.org/10.48550/arXiv.2309.17277](https://doi.org/10.48550/arXiv.2309.17277)
93. Holt, S., Luyten, M. R., & Schaar, M. van der. (2024). _L2MAC: Large Language Model Automatic Computer for Extensive Code Generation_ (No. arXiv: 2310.02003). arXiv. [https://doi.org/10.48550/arXiv.2310.02003](https://doi.org/10.48550/arXiv.2310.02003)
94. Ifargan, T., Hafner, L., Kern, M., Alcalay, O., & Kishony, R. (2024). _Autonomous LLM-driven research from data to human-verifiable research papers_ (No. arXiv: 2404.17605). arXiv. [https://doi.org/10.48550/arXiv.2404.17605](https://doi.org/10.48550/arXiv.2404.17605)
95. Qian, C., Liu, W., Liu, H., Chen, N., Dang, Y., Li, J., Yang, C., Chen, W., Su, Y., Cong, X., Xu, J., Li, D., Liu, Z., & Sun, M. (2024). _ChatDev: Communicative Agents for Software Development_ (No. arXiv: 2307.07924). arXiv. [https://doi.org/10.48550/arXiv.2307.07924](https://doi.org/10.48550/arXiv.2307.07924)
96. Shen, Y., Song, K., Tan, X., Li, D., Lu, W., & Zhuang, Y. (2023). _HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face_ (No. arXiv: 2303.17580). arXiv. [https://doi.org/10.48550/arXiv.2303.17580](https://doi.org/10.48550/arXiv.2303.17580)
97. Singh, A., Ehtesham, A., Kumar, S., & Khoei, T. T. (2025). _Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG_ (No. arXiv: 2501.09136). arXiv. [https://doi.org/10.48550/arXiv.2501.09136](https://doi.org/10.48550/arXiv.2501.09136)
98. Wang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L., & Anandkumar, A. (2023). _Voyager: An Open-Ended Embodied Agent with Large Language Models_ (No. arXiv: 2305.16291). arXiv. [https://doi.org/10.48550/arXiv.2305.16291](https://doi.org/10.48550/arXiv.2305.16291)
99. Wang, L., Xu, W., Lan, Y., Hu, Z., Lan, Y., Lee, R. K.-W., & Lim, E.-P. (2023). _Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models_ (No. arXiv: 2305.04091). arXiv. [https://doi.org/10.48550/arXiv.2305.04091](https://doi.org/10.48550/arXiv.2305.04091)
100. Wu, Q., Bansal, G., Zhang, J., Wu, Y., Li, B., Zhu, E., Jiang, L., Zhang, X., Zhang, S., Liu, J., Awadallah, A. H., White, R. W., Burger, D., & Wang, C. (2023). _AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation_ (No. arXiv: 2308.08155). arXiv. [https://doi.org/10.48550/arXiv.2308.08155](https://doi.org/10.48550/arXiv.2308.08155)
101. Xie, T., Zhou, F., Cheng, Z., Shi, P., Weng, L., Liu, Y., Hua, T. J., Zhao, J., Liu, Q., Liu, C., Liu, L. Z., Xu, Y., Su, H., Shin, D., Xiong, C., & Yu, T. (2023). _OpenAgents: An Open Platform for Language Agents in the Wild_ (No. arXiv: 2310.10634). arXiv. [https://doi.org/10.48550/arXiv.2310.10634](https://doi.org/10.48550/arXiv.2310.10634)
102. Zhang, A., Chen, Y., Sheng, L., Wang, X., & Chua, T.-S. (2024). _On Generative Agents in Recommendation_ (No. arXiv: 2310.10108). arXiv. [https://doi.org/10.48550/arXiv.2310.10108](https://doi.org/10.48550/arXiv.2310.10108)
103. Zhou, W., Jiang, Y. E., Li, L., Wu, J., Wang, T., Qiu, S., Zhang, J., Chen, J., Wu, R., Wang, S., Zhu, S., Chen, J., Zhang, W., Tang, X., Zhang, N., Chen, H., Cui, P., & Sachan, M. (2023). _Agents: An Open-source Framework for Autonomous Language Agents_ (No. arXiv: 2309.07870). arXiv. [https://doi.org/10.48550/arXiv.2309.07870](https://doi.org/10.48550/arXiv.2309.07870)
104. Zhuge, M., Liu, H., Faccio, F., Ashley, D. R., Csord√°s, R., Gopalakrishnan, A., Hamdi, A., Hammoud, H. A. A. K., Herrmann, V., Irie, K., Kirsch, L., Li, B., Li, G., Liu, S., Mai, J., Piƒôkos, P., Ramesh, A., Schlag, I., Shi, W., ‚Ä¶ Schmidhuber, J. (2023). _Mindstorms in Natural Language-Based Societies of Mind_ (No. arXiv: 2305.17066). arXiv. [https://doi.org/10.48550/arXiv.2305.17066](https://doi.org/10.48550/arXiv.2305.17066)

## RAG

### ÊïôÁ®ãÊ±áÊÄª

- [GitHub - NirDiamant/RAG\_Techniques: This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.](https://github.com/NirDiamant/RAG_Techniques)
- [GitHub - bRAGAI/bRAG-langchain: Everything you need to know to build your own RAG application](https://github.com/bRAGAI/bRAG-langchain)
- [GitHub - D-Star-AI/dsRAG: High-performance retrieval engine for unstructured data](https://github.com/D-Star-AI/dsRAG)

### KRAG

- [GitHub - microsoft/SmartKG: This project accepts excel files as input which contains the description of a Knowledge Graph (Vertexes and Edges) and convert it into an in-memory Graph Store. This project implements APIs to search/filter/get nodes and relations from the in-memory Knowledge Graph. This project also provides a dialog management framework and enable a chatbot based on its knowledge graph.](https://github.com/microsoft/SmartKG)
- [GitHub - CheMiguel23/MemoryMesh: A knowledge graph server that uses the Model Context Protocol (MCP) to provide structured memory persistence for AI models. v0.2.8](https://github.com/CheMiguel23/MemoryMesh)
- [GitHub - shaneholloman/mcp-knowledge-graph: MCP server enabling persistent memory for Claude through a local knowledge graph - fork focused on local development](https://github.com/shaneholloman/mcp-knowledge-graph)

## Agent Document

- [Blog \| Letta](https://www.letta.com/blog)
- [The Letta Platform ‚Äî Letta](https://docs.letta.com/letta-platform)
- [LangGraph](https://langchain-ai.github.io/langgraph/)
- [ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/introduction/)
- [Get started with LangSmith \| ü¶úÔ∏èüõ†Ô∏è LangSmith](https://docs.smith.langchain.com/)

## AI‰ª£ÁêÜÂÖ≥ÈîÆÊäÄÊúØÊñπÊ°àÊÄªÁªì

### ÂÜÖÂ≠òÁÆ°ÁêÜÊñπÊ°à

1. **ÈïøÁü≠ÊúüËÆ∞ÂøÜÁªìÊûÑ**
   - **ÈïøÊúüËÆ∞ÂøÜ**ÔºöÈÄöÂ∏∏ÈÄöËøáÂêëÈáèÊï∞ÊçÆÂ∫ìÔºàÂ¶ÇPinecone„ÄÅChroma„ÄÅMilvusÔºâÂÆûÁé∞Ôºå‰ΩøÁî®ËØ≠‰πâÊêúÁ¥¢Ê£ÄÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöPineconeÂú®CiscoÁöÑ‰ºÅ‰∏öAIÂä©Êâã‰∏≠Áî®‰∫éÂáÜÁ°Æ„ÄÅÂÆâÂÖ®Âú∞ÊêúÁ¥¢Êï∞Áôæ‰∏áÊñáÊ°£
     - **Â∫îÁî®ÂÆû‰æã**ÔºöBabyAGI‰ΩøÁî®PineconeÂ≠òÂÇ®‰ªªÂä°ÊâßË°åÂéÜÂè≤ÔºåÂç≥‰ΩøÂÖ≥Èó≠Âêé‰πüËÉΩ‰øùÊåÅËÆ∞ÂøÜ
   - **Áü≠ÊúüËÆ∞ÂøÜÔºàÂ∑•‰ΩúËÆ∞ÂøÜÔºâ**ÔºöÁî±LLMÁª¥Êä§ÂíåÊõ¥Êñ∞ÔºåÁî®‰∫éÂΩìÂâçÂØπËØùÊàñ‰ªªÂä°‰∏ä‰∏ãÊñá
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangChainÁöÑConversationBufferMemory‰øùÂ≠òÂÆåÊï¥ÂØπËØùÂéÜÂè≤
     - **Â∫îÁî®ÂÆû‰æã**ÔºöAutoGen‰∏≠ÁöÑ‰ª£ÁêÜÂèØ‰ª•Âú®ÂØπËØùÊúüÈó¥Áª¥Êä§Áü≠Êúü‰∏ä‰∏ãÊñá
1. **ËÆ∞ÂøÜÊåÅ‰πÖÂåñÊñπÊ°à**
   - **ÂÆåÊï¥Áä∂ÊÄÅÂ∫èÂàóÂåñ**ÔºöÂ∞Ü‰ª£ÁêÜÁöÑÂÆåÊï¥Áä∂ÊÄÅÔºàÂåÖÊã¨ËÆ∞ÂøÜÂíåÂ∑•ÂÖ∑Áä∂ÊÄÅÔºâ‰øùÂ≠òÂà∞Êñá‰ª∂ÊàñPythonÂØπË±°‰∏≠
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLettaÔºàÂâçË∫´‰∏∫MemGPTÔºâÂèØ‰ª•Â∞Ü‰ª£ÁêÜÁä∂ÊÄÅÂ∫èÂàóÂåñÔºåÊó†ÈúÄÂ§ñÈÉ®Êï∞ÊçÆÂ∫ì
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangGraphÁöÑMemory StoreÊèê‰æõ‰ΩéÁ∫ßÊäΩË±°ÔºåËÆ©Áî®Êà∑ÂÆåÂÖ®ÊéßÂà∂‰ª£ÁêÜËÆ∞ÂøÜ
   - **‰ºöËØùÊåÅ‰πÖËÆ∞ÂøÜ**ÔºöÁ°Æ‰øùÊï∞ÊçÆÂú®Â§ö‰∏™‰ºöËØù‰πãÈó¥‰øùÂ≠ò
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLettaÁöÑÊ†∏ÂøÉËÆ∞ÂøÜÂäüËÉΩÂÖÅËÆ∏‰ª£ÁêÜËÆ∞‰ΩèÁî®Êà∑‰ø°ÊÅØÔºàÂ¶ÇÂêçÂ≠óÔºâÔºåÂç≥‰ΩøÂú®‰ºöËØùÁªìÊùüÂêé
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangChainÁöÑConversationEntityMemoryÂèØ‰ª•Ë∑üË∏™ÂØπËØù‰∏≠ÊèêÂà∞ÁöÑÂÆû‰Ωì
   - **Êó†ÈôêËÆ∞ÂøÜÂõûÂøÜ**ÔºöÂ¶ÇBabyAGIÁöÑ‰∏Ä‰∫õÂèò‰ΩìÔºåÂèØ‰ª•ÂõûÂøÜ"Êó†Èôê"ËÆ∞ÂøÜÔºåÂç≥‰ΩøÂú®ÂÖ≥Èó≠Âêé‰πü‰∏ç‰ºö‰∏¢Â§±ËÆ∞ÂøÜ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöBabyAGIÁöÑÂèò‰Ωì‰ΩøÁî®PineconeÂêëÈáèÊï∞ÊçÆÂ∫ìÂíåËÆ∞ÂøÜËÆ°Êï∞Âô®‰øùÂ≠òÁ¥¢Âºï‰ΩçÁΩÆ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöMemGPT‰ΩøÁî®Â§öÂ±ÇËÆ∞ÂøÜÊû∂ÊûÑÔºåÂÖÅËÆ∏Êó†ÈôêÂà∂ÁöÑËÆ∞ÂøÜÂÆπÈáè
1. **ËÆ∞ÂøÜÁÆ°ÁêÜÊäÄÊúØ**
   - **Ëá™ÁºñËæëËÆ∞ÂøÜ**ÔºöÂÖÅËÆ∏ËÅäÂ§©Êú∫Âô®‰∫∫Ëá™ÊàëÁºñËæëÂÖ∂ËÆ∞ÂøÜ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLettaÁöÑcore_memory_replaceÂäüËÉΩÂÖÅËÆ∏‰ª£ÁêÜÊõ¥Êñ∞Ê†∏ÂøÉËÆ∞ÂøÜÔºàÂ¶ÇÁî®Êà∑ÂêçÂ≠óÔºâ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöMemGPTÁöÑstore_messageÂäüËÉΩÂÖÅËÆ∏‰ª£ÁêÜÂ≠òÂÇ®ÈáçË¶ÅÁöÑÁî®Êà∑ÁªÜËäÇ
   - **ÂàÜÂ±ÇËÆ∞ÂøÜÁÆ°ÁêÜ**ÔºöÊô∫ËÉΩÁÆ°ÁêÜ‰∏çÂêåÂ±ÇÁ∫ßÁöÑËÆ∞ÂøÜÔºåÂú®LLMÊúâÈôêÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÂÜÖÊúâÊïàÊèê‰æõÊâ©Â±ï‰∏ä‰∏ãÊñá
     - **Â∫îÁî®ÂÆû‰æã**ÔºöMemGPTÁöÑ‰∏âÂ±ÇËÆ∞ÂøÜÊû∂ÊûÑÔºöÊ†∏ÂøÉËÆ∞ÂøÜ„ÄÅÂõûÂøÜËÆ∞ÂøÜÂíåÂΩíÊ°£ËÆ∞ÂøÜ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangChainÁöÑConversationSummaryBufferMemoryÈÄöËøáÊÄªÁªìÂéãÁº©ÈïøÂØπËØù
   - **ËÆ∞ÂøÜÊÄªÁªì**ÔºöÈÄöËøáÊÄªÁªìÂéãÁº©ÈïøÊúüËÆ∞ÂøÜÔºå‰øùÁïôÂÖ≥ÈîÆ‰ø°ÊÅØ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangChainÁöÑConversationSummaryMemoryÂàõÂª∫ÂØπËØùÊëòË¶ÅËÄåÈùûÂ≠òÂÇ®ÂÆåÊï¥ÂéÜÂè≤
     - **Â∫îÁî®ÂÆû‰æã**ÔºöMemGPTÂèØ‰ª•Â∞ÜÂØπËØùÊÄªÁªì‰∏∫ÂèØÈáçÁî®ÁöÑËÆ∞ÂøÜ
1. **ËÆ∞ÂøÜÊ£ÄÁ¥¢Á≠ñÁï•**
   - **Áõ∏ÂÖ≥ÊÄßÊü•ËØ¢**ÔºöAIÂú®ÂÖ∂ËÆ∞ÂøÜ‰∏≠Êü•Êâæ‰∏éÂΩìÂâçÊü•ËØ¢Áõ∏ÂÖ≥ÁöÑËÆ∞ÂøÜÂíåËøáÂéªÁöÑÊü•ËØ¢
     - **Â∫îÁî®ÂÆû‰æã**ÔºöMemGPTÁöÑconversation_searchÂäüËÉΩÂÖÅËÆ∏ÊêúÁ¥¢Êï¥‰∏™Ê∂àÊÅØÂéÜÂè≤
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangChainÁöÑVectorStoreRetrieverMemory‰ΩøÁî®ÂêëÈáèÁõ∏‰ººÊÄßÊ£ÄÁ¥¢Áõ∏ÂÖ≥ËÆ∞ÂøÜ
   - **ËÆ∞ÂøÜÁ¥¢Âºï**Ôºö‰ΩøÁî®ËÆ°Êï∞Âô®‰øùÂ≠òÁ¥¢Âºï‰ΩçÁΩÆÔºå‰æø‰∫éÈ´òÊïàÊ£ÄÁ¥¢
     - **Â∫îÁî®ÂÆû‰æã**ÔºöBabyAGIÂèò‰Ωì‰ΩøÁî®ËÆ∞ÂøÜËÆ°Êï∞Âô®‰øùÂ≠òÁ¥¢Âºï‰ΩçÁΩÆ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöPineconeÁöÑÁ¥¢ÂºïÂäüËÉΩÊîØÊåÅÈ´òÊïàÁöÑÂêëÈáèÊêúÁ¥¢
1. **ËÆ∞ÂøÜÁ±ªÂûã‰∏éÂÆûÁé∞Ê°ÜÊû∂**
   - **ÂØπËØùËÆ∞ÂøÜ**ÔºöÂ≠òÂÇ®ÂíåÊ£ÄÁ¥¢ÂØπËØùÂéÜÂè≤
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangChainÊèê‰æõÂ§öÁßçÂØπËØùËÆ∞ÂøÜÁ±ªÂûãÔºöBuffer„ÄÅSummary„ÄÅEntity„ÄÅKnowledgeGraph
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangGraphÁöÑReAct Memory AgentÂèØ‰ª•‰øùÂ≠òÁî®Êà∑ÂÅèÂ•ΩÔºåË∑®ÂØπËØùÁ∫øÁ®ã‰ΩøÁî®
   - **ÂêëÈáèËÆ∞ÂøÜ**Ôºö‰ΩøÁî®ÂµåÂÖ•ÂêëÈáèÂ≠òÂÇ®ÂíåÊ£ÄÁ¥¢‰ø°ÊÅØ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöPineconeÁî®‰∫éRAGÔºàÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºâÂ∫îÁî®ÔºåÊèê‰æõÂáÜÁ°ÆÁöÑÁü•ËØÜÊ£ÄÁ¥¢
     - **Â∫îÁî®ÂÆû‰æã**ÔºöMilvus LiteÁî®‰∫é‰∏∫LangChain‰ª£ÁêÜÊèê‰æõÈïøÊúüËÆ∞ÂøÜ
   - **ÁªÑÁªáËÆ∞ÂøÜ**Ôºö‰∏∫Âõ¢ÈòüÂçè‰ΩúËÆæËÆ°ÁöÑËÆ∞ÂøÜÁ≥ªÁªü
     - **Â∫îÁî®ÂÆû‰æã**ÔºöÊüê‰∫õÈó≠Ê∫êÈ°πÁõÆ‰∏ìÊ≥®‰∫éÁªÑÁªáËÆ∞ÂøÜÂíåÂõ¢ÈòüÂçè‰Ωú
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangChainÁöÑMemory StoreÂèØ‰ª•Ê†πÊçÆÁî®Êà∑IDËåÉÂõ¥ÂåñËÆ∞ÂøÜ
1. **Áü•ËØÜÂõæË∞±ËÆ∞ÂøÜ**
   - **ÂõæÁªìÊûÑË°®Á§∫**Ôºö‰ΩøÁî®ËäÇÁÇπÂíåËæπË°®Á§∫ÂÆû‰ΩìÂèäÂÖ∂ÂÖ≥Á≥ªÔºåÊèê‰æõÁªìÊûÑÂåñÁöÑÁü•ËØÜË°®Á§∫
     - **Â∫îÁî®ÂÆû‰æã**ÔºöFalkorDBÊèê‰æõË∂Ö‰ΩéÂª∂ËøüÂõæÊï∞ÊçÆÂ∫ìËß£ÂÜ≥ÊñπÊ°àÔºå‰ºòÂåñAI‰ª£ÁêÜÁöÑÁü•ËØÜÂ≠òÂÇ®
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangChainÁöÑConversationKnowledgeGraphMemoryÊûÑÂª∫ÂØπËØù‰∏≠ÂÆû‰ΩìÁöÑÂÖ≥Á≥ªÂõæ
   - **Â§öÊ≠•Êé®ÁêÜËÉΩÂäõ**ÔºöÈÄöËøáÈÅçÂéÜÂÖ≥Á≥ªÂõæËøõË°åÂ§çÊùÇÊé®ÁêÜÂíåÂÜ≥Á≠ñ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöZepÁöÑÊó∂Èó¥Áü•ËØÜÂõæË∞±ÂèØ‰ª•Ë∑üË∏™‰∫ãÂÆûÂ¶Ç‰ΩïÈöèÊó∂Èó¥ÂèòÂåñ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöÂõæÊï∞ÊçÆÂ∫ìÊîØÊåÅÂ§çÊùÇÊü•ËØ¢Ôºå‰Ωø‰ª£ÁêÜËÉΩÂ§üÊâßË°åÂ§çÊùÇÂàÜÊûêÂπ∂‰∫ßÁîüÊõ¥Â•ΩÁöÑÁªìÊûú
   - **ËØ≠‰πâÂÖ≥Á≥ª‰øùÂ≠ò**Ôºö‰øùÊåÅÂÆû‰ΩìÈó¥ÁöÑÂ§çÊùÇËØ≠‰πâÂÖ≥Á≥ªÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÁÆÄÂçïÁöÑÈîÆÂÄºÂØπ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöSAPÁü•ËØÜÂõæË∞±ÈÄöËøáËøûÊé•SAPÊï∞ÊçÆ‰∏é‰∏öÂä°‰∏ä‰∏ãÊñáÔºåÈáäÊîæÊï∞ÊçÆÂÖ®ÈÉ®‰ª∑ÂÄº
     - **Â∫îÁî®ÂÆû‰æã**ÔºöZepÁöÑÁü•ËØÜÂõæË∞±Êô∫ËÉΩËûçÂêàËÅäÂ§©Ê∂àÊÅØÂíå‰∏öÂä°Êï∞ÊçÆ
1. **ÂÆû‰ΩìËÆ∞ÂøÜ**
   - **ÂÆû‰ΩìÊèêÂèñ‰∏éÊÄªÁªì**Ôºö‰ªéÂØπËØù‰∏≠ÊèêÂèñÂëΩÂêçÂÆû‰ΩìÂπ∂ÁîüÊàêÊëòË¶Å
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangChainÁöÑConversationEntityMemory‰ªéÊúÄËøëÁöÑËÅäÂ§©ÂéÜÂè≤‰∏≠ÊèêÂèñÂëΩÂêçÂÆû‰Ωì
     - **Â∫îÁî®ÂÆû‰æã**ÔºöÂÆû‰ΩìËÆ∞ÂøÜÂèØ‰ª•Ë∑üË∏™ÂØπËØù‰∏≠ÊèêÂà∞ÁöÑ‰∫∫Áâ©„ÄÅÂú∞ÁÇπ„ÄÅÁªÑÁªáÁ≠â
   - **ÂÆû‰ΩìÂ≠òÂÇ®**Ôºö‰ΩøÁî®ÂèØ‰∫§Êç¢ÁöÑÂÆû‰ΩìÂ≠òÂÇ®ÔºåÂú®ÂØπËØùÈó¥ÊåÅ‰πÖÂåñÂÆû‰Ωì
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangChainÊîØÊåÅÂ§öÁßçÂÆû‰ΩìÂ≠òÂÇ®ÔºöÂÜÖÂ≠ò„ÄÅRedis„ÄÅSQLiteÁ≠â
     - **Â∫îÁî®ÂÆû‰æã**ÔºöÂÆû‰ΩìËÆ∞ÂøÜÂèØ‰ª•ËÆ∞‰Ωè"SamÊòØDaimonÂÖ¨Âè∏ÁöÑÂàõÂßã‰∫∫"Á≠âÂÖ≥ÈîÆ‰∫ãÂÆû
   - **ÂÆû‰ΩìÊõ¥Êñ∞**ÔºöÈöèÁùÄÂØπËØùËøõË°åÔºå‰∏çÊñ≠Êõ¥Êñ∞Âíå‰∏∞ÂØåÂÆû‰Ωì‰ø°ÊÅØ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöÂΩìËé∑ÂèñÊñ∞‰ø°ÊÅØÊó∂ÔºåÂÆû‰ΩìËÆ∞ÂøÜ‰ºöÊõ¥Êñ∞Áé∞ÊúâÂÆû‰ΩìÁöÑÊèèËø∞
     - **Â∫îÁî®ÂÆû‰æã**ÔºöZepÊ†áËÆ∞ËøáÊó∂ÁöÑ‰∫ãÂÆû‰∏∫Êó†ÊïàÔºå‰øùÊåÅÂÆû‰Ωì‰ø°ÊÅØÁöÑÊúÄÊñ∞Áä∂ÊÄÅ
1. **Áî®Êà∑ÁîªÂÉèËÆ∞ÂøÜ**
   - **Áî®Êà∑ÂÅèÂ•ΩË∑üË∏™**ÔºöËÆ∞ÂΩïÁî®Êà∑ÁöÑÂÅèÂ•Ω„ÄÅÂÖ¥Ë∂£ÂíåË°å‰∏∫Ê®°Âºè
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLangGraphÁöÑMemory StoreÂèØ‰ª•Ê†πÊçÆÁî®Êà∑IDÂ≠òÂÇ®Áî®Êà∑ÁâπÂÆöÁöÑËÆ∞ÂøÜ
     - **Â∫îÁî®ÂÆû‰æã**ÔºöZepÂèØ‰ª•‰∏∫ÊØè‰∏™Áî®Êà∑ÊûÑÂª∫‰∏™ÊÄßÂåñÁöÑÁü•ËØÜÂõæË∞±
   - **‰∏™ÊÄßÂåñÂìçÂ∫îÁîüÊàê**ÔºöÂü∫‰∫éÁî®Êà∑ÁîªÂÉèÂÆöÂà∂ÂõûÂ§ç
     - **Â∫îÁî®ÂÆû‰æã**ÔºöÈ´òÂ∫¶‰∏™ÊÄßÂåñÁöÑAIÂä©ÊâãÂèØ‰ª•ËÆ∞‰ΩèÊâÄÊúâÁî®Êà∑ÂÅèÂ•ΩÂíå‰πãÂâçÁöÑ‰∫§‰∫í
     - **Â∫îÁî®ÂÆû‰æã**ÔºöZepÁöÑÊó∂Èó¥Êé®ÁêÜËÉΩÂäõ‰Ωø‰ª£ÁêÜËÉΩÂ§üÁêÜËß£Áî®Êà∑Áä∂ÊÄÅÁöÑÂèòÂåñ
   - **Ë∑®‰ºöËØùÁî®Êà∑ËØÜÂà´**ÔºöÂú®Â§ö‰∏™‰ºöËØù‰∏≠ËØÜÂà´ÂíåËÆ∞‰ΩèÂêå‰∏ÄÁî®Êà∑
     - **Â∫îÁî®ÂÆû‰æã**ÔºöLettaÂèØ‰ª•Âú®Áî®Êà∑ÂÜçÊ¨°ÁôªÂΩïÊó∂ËÆ∞‰ΩèÂØπËØùÁªÜËäÇ
     - **Â∫îÁî®ÂÆû‰æã**Ôºö‰ºÅ‰∏öÁ∫ßËÆ∞ÂøÜÁ≥ªÁªüÊîØÊåÅSOC 2 Type IIÂêàËßÑÂíåÈöêÁßÅÊéßÂà∂

### Â§ö‰ª£ÁêÜÂçè‰ΩúÊñπÊ°à

1. **ÊéßÂà∂Âô®Êû∂ÊûÑ**
   - **Âä®ÊÄÅÂÜ≥Á≠ñÊéßÂà∂Âô®**Ôºö‰ΩøÁî®LLMÂä®ÊÄÅÂÜ≥ÂÆö‰∏ã‰∏Ä‰∏™ÊâßË°åÂä®‰ΩúÁöÑ‰ª£ÁêÜÔºåËÄÉËôëÂÖàÂâçÁöÑÂä®‰Ωú„ÄÅÁéØÂ¢ÉÂíåÂΩìÂâçÁä∂ÊÄÅÁöÑÁõÆÊ†á
   - **Á¨¶Âè∑ÊéßÂà∂**Ôºö‰ΩøÁî®Ê†áÂáÜÊìç‰ΩúÊµÅÁ®ã(SOP)ÂÆö‰πâÊï¥‰Ωì‰ªªÂä°ÁöÑÂ≠êÁõÆÊ†á/Â≠ê‰ªªÂä°
1. **‰ª£ÁêÜËßíËâ≤ÂàÜÈÖç**
   - **‰∏ìÂÆ∂‰ª£ÁêÜ**ÔºöÊØè‰∏™‰ª£ÁêÜÊâÆÊºîÁâπÂÆö‰∏ì‰∏öÈ¢ÜÂüüÁöÑ‰∏ìÂÆ∂ËßíËâ≤
   - **ËßíËâ≤ÊâÆÊºî‰ª£ÁêÜ**Ôºö‰ª£ÁêÜÂÖ∑ÊúâÁâπÂÆöËßíËâ≤„ÄÅËÉåÊôØÊïÖ‰∫ã„ÄÅÁõÆÊ†áÂíåËÆ∞ÂøÜ
   - **‰∫∫Êú∫‰∫§‰∫í**ÔºöÊ°ÜÊû∂ÊîØÊåÅ‰∫∫Á±ªÁî®Êà∑ÊâÆÊºî‰ª£ÁêÜËßíËâ≤ÔºåËæìÂÖ•Ëá™Â∑±ÁöÑÂä®‰ΩúÔºå‰∏éÁéØÂ¢É‰∏≠ÁöÑÂÖ∂‰ªñËØ≠Ë®Ä‰ª£ÁêÜ‰∫§‰∫í
1. **Âçè‰ΩúÊ®°Âºè**
   - **ÂØπËØùÂºèÂçè‰Ωú**Ôºö‰ª£ÁêÜÈÄöËøáÂØπËØù‰∫§ÊµÅ‰ø°ÊÅØÂíåÊÉ≥Ê≥ï
   - **‰ªªÂä°ÂàÜËß£Âçè‰Ωú**ÔºöÂ∞ÜÂ§çÊùÇ‰ªªÂä°ÂàÜËß£‰∏∫Â≠ê‰ªªÂä°ÔºåÁî±‰∏çÂêå‰ª£ÁêÜÂ§ÑÁêÜ
   - **Â±ÇÊ¨°Âçè‰Ωú**Ôºö‰ª£Ë°®‰ª£ÁêÜÈó¥Âçè‰ΩúÁöÑÂ±ÇÊ¨°ÁªìÊûÑ
1. **Â§öLLMÁ≥ªÁªü**
   - **Ê∑∑ÂêàÂº∫Â∫¶Ê®°Âûã**ÔºöÂØπÈúÄË¶ÅÂº∫Êé®ÁêÜÂíåÊåá‰ª§ÈÅµÂæ™ÁöÑ‰ª£ÁêÜ‰ΩøÁî®Êõ¥Âº∫Â§ßÁöÑLLMÔºåÂ∞ÜÁÆÄÂçï‰ªªÂä°ÂßîÊâòÁªôËæÉÂº±/Êú¨Âú∞LLM
   - **Ëá™Âä®Âõæ‰ºòÂåñÂô®**Ôºö‰ºòÂåñËäÇÁÇπÁ∫ßLLMÊèêÁ§∫ÂíåÊîπËøõ‰ª£ÁêÜÁºñÊéí

### Â∑•ÂÖ∑‰ΩøÁî®ÊñπÊ°à

1. **Â∑•ÂÖ∑ÈõÜÊàêÊäÄÊúØ**
   - **ÂáΩÊï∞Ë∞ÉÁî®**ÔºöÈÄöËøáOpenAIÁöÑfunction-callingÊàñÁ±ª‰ººÊú∫Âà∂ÈõÜÊàêÂ§ñÈÉ®Â∑•ÂÖ∑
   - **Ëá™ÂÆö‰πâÂ∑•ÂÖ∑/API**ÔºöÂºÄÂèëËÄÖÂèØ‰ª•Ê∑ªÂä†Ëá™ÂÆö‰πâÂ∑•ÂÖ∑ÂíåAPI
   - **Â∑•ÂÖ∑Ê∂àÊÅØ**ÔºöÊîØÊåÅ‰∏éÂáΩÊï∞Ë∞ÉÁî®Á≠âÊïàÁöÑÂéüÁîüToolMessage
1. **Â∑•ÂÖ∑Á±ªÂûã**
   - **ÊêúÁ¥¢Â∑•ÂÖ∑**ÔºöÁªìÂêàÊêúÁ¥¢„ÄÅÊäìÂèñ„ÄÅÂàÜÂùóÂíåÊèêÂèñÂäüËÉΩ
   - **Ëø∑‰Ω†‰ª£ÁêÜÂ∑•ÂÖ∑**ÔºöÂ∞ÜÂ∞èÂûã‰∏ìÁî®‰ª£ÁêÜ‰Ωú‰∏∫Â∑•ÂÖ∑‰ΩøÁî®
   - **ÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑**ÔºöÊâßË°åshellÂëΩ‰ª§ÁöÑËÉΩÂäõ
   - **‰∏ì‰∏öÈ¢ÜÂüüÂ∑•ÂÖ∑**ÔºöÂ¶ÇChemCrowÈõÜÊàêÁöÑ13Áßç‰∏ìÂÆ∂ËÆæËÆ°Â∑•ÂÖ∑ÔºåÂ¢ûÂº∫LLMÂú®ÂåñÂ≠¶È¢ÜÂüüÁöÑÊÄßËÉΩ
1. **Â∑•ÂÖ∑‰ΩøÁî®Ê®°Âºè**
   - **ReActÊ®°Âºè**ÔºöÊÄùËÄÉ„ÄÅË°åÂä®„ÄÅË°åÂä®ËæìÂÖ•„ÄÅËßÇÂØüÁöÑÂæ™ÁéØÊ®°Âºè
   - **Â∑•ÂÖ∑‰ª£ÁêÜ**Ôºö‰∏∫Â≠ê‰ªªÂä°Êèê‰æõÊúÄ‰Ω≥Ë°åÂä®Á≥ªÂàóÁöÑ‰∏ìÁî®‰ª£ÁêÜ
   - **Â∑•ÂÖ∑ËÆæËÆ°‰∏éË∞ÉËØï**ÔºöËÉΩÂ§üËÆæËÆ°„ÄÅÁºñÁ†ÅÂíåË∞ÉËØïËá™Â∑±ÁöÑÂ∑•ÂÖ∑
1. **ËßÑÂàí‰∏éÊâßË°å**
   - **Plan-and-SolveÊñπÊ≥ï**ÔºöÈÄöËøáÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊîπËøõÈõ∂Ê†∑Êú¨ÈìæÂºèÊÄùËÄÉÊé®ÁêÜ
   - **‰ªªÂä°ËßÑÂàí**Ôºö‰ΩøÁî®ChatGPTÂàÜÊûêÁî®Êà∑ËØ∑Ê±ÇÔºåÁêÜËß£ÊÑèÂõæÂπ∂ÂàÜËß£‰∏∫ÂèØËß£ÂÜ≥ÁöÑ‰ªªÂä°
   - **Â∑•‰ΩúÊµÅÊ≠•È™§ÊâπÂáÜ**ÔºöÂú®Áõ∏ÂÖ≥Â∑•‰ΩúÊµÅÊ≠•È™§ËØ∑Ê±ÇÊâπÂáÜÔºåÁ°Æ‰øùÊâßË°åÈ¢ÑÊúüÊìç‰Ωú
